---
title: Step by step guide
output: 
  rmarkdown::html_document:
    fig_width: 7
    fig_height: 6
    fig_caption: yes
    keep_md: yes
    self_contained: yes
    theme: readable
---

```{r chunk-setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
This workflow should show full strength of *RRatepol package* and serve as step by 
step guidance starting from downloading dataset from Neotoma, building age-depth
models, to estimating rate-of-change using age uncertainty.

:warning: **This workflow is only meant as example**: There are several additional steps for data reparation which should be done to really use the data from Neotoma!

## Install packages
```{r renv-check, include=FALSE, results='hide', warning=FALSE, message=FALSE} 
if (
  !require(renv)
) {
  install.packages("renv")
  library(renv)
}
```

Make a list of packages needed to from CRAN

```{r pkg-list, results='hide', warning=FALSE, message=FALSE}
package_list <-
  c(
    "tidyverse", # general data wrangling and visualisation
    "pander", # nice tables
    "Bchron", # age-depth modeling
    "janitor", # string cleaning
    "remotes" # installing packages from GitHub
  )
```

Install all packages from CRAN using `{renv}` package

```{r pkg-install, eval = FALSE}
lapply(
  package_list, renv::use
)
```

Install packages from GitHub

```{r pkg-install-gh, eval = FALSE}
# Install R-Ratepol
remotes::install_github("HOPE-UIB-BIO/R-Ratepol-package")

# Install neotoma2
remotes::install_github("NeotomaDB/neotoma2")
```

## Attach packages

```{r pkg-attach, results='hide', warning=FALSE, message=FALSE}
library(tidyverse) # general data wrangling and visualisation
library(pander) # nice tables
library(RRatepol) # rate-of-vegetation change
library(neotoma2) # obtain data from Neotoma database
library(Bchron) # age-depth modeling
library(janitor) # string cleaning
```

## Download a dataset from Neotoma

Here we have selected the **XXX** record.

```{r download_of_data, results='hide', warning=FALSE, message=FALSE}
sel_dataset_download <-
  neotoma2::get_downloads(52406)

sel_chron_control_table_download <-
  neotoma2::chroncontrols(sel_dataset_download)
```

## Prepare the pollen counts

```{r count_preparation, results='hide', warning=FALSE}
sel_counts <-
  neotoma2::samples(sel_dataset_download)

sel_taxon_list_selected <-
  neotoma2::taxa(sel_dataset_download) %>%
  dplyr::filter(element == "pollen") %>%
  purrr::pluck("variablename")

sel_counts_selected <-
  sel_counts %>%
  as.data.frame() %>%
  dplyr::mutate(sample_id = as.character(sampleid)) %>%
  tibble::as_tibble() %>%
  dplyr::select("sample_id", "value", "variablename") %>%
  dplyr::filter(
    variablename %in% sel_taxon_list_selected
  ) %>%
  tidyr::pivot_wider(
    names_from = "variablename",
    values_from = "value",
    values_fill = 0
  ) %>%
  janitor::clean_names()

head(sel_counts_selected)[, 1:5]
```

```{r count_diplay, echo=FALSE, results='asis', warning=FALSE, message=FALSE}
pander::pandoc.table(head(sel_counts_selected)[, 1:5])
```

Here, we strongly advocate that attention should be paid to the section of 
ecological ecological group, as well, as harmonisation of the pollen taxa.
However, that is not subject of this workflow.

## Preparation of the levels

### Sample depth

Extract depth for each level

```{r level_preparion, results='hide', warning=FALSE}
sel_level <-
  neotoma2::samples(sel_dataset_download) %>%
  tibble::as_tibble() %>%
  dplyr::mutate(sample_id = as.character(sampleid)) %>%
  dplyr::distinct(sample_id, depth) %>%
  dplyr::relocate(sample_id)

head(sel_level)
```

```{r level_diplay, echo=FALSE, results='asis', warning=FALSE, message=FALSE}
pander::pandoc.table(head(sel_level))
```


### Age depth modelling

We will recalculate new age-depth model 'de novo' using *Bchron* package. In this 
toy example we will use only iteration multiplier (*i_multiplier*) of 0.5 to 
reduce the computation time. However, we strongly recommend to increase it to 5
for any normal age-depth model construction.

Prepare chron.control table and run Bchron
Here we only present few of the important steps of preparation of chron.control 
table. There are many more potential issues issues but solving those is not 
the focus of this workflow.

```{r chron_control_prepare, results='hide', warning=FALSE}
# first check which chronologies were used
print(sel_chron_control_table_download)

# prepare the table
sel_chron_control_table <-
  sel_chron_control_table_download %>%
  dplyr::filter(chronologyid == 37274) %>%
  tibble::as_tibble() %>%
  # here we calculate the error as the avarage as the agelimitolder and
  #   agelimityounger
  dplyr::mutate(
    error = round((agelimitolder - agelimityounger) / 2)
  ) %>%
  # as Bchron cannot accept error of 0, we need to replace the value with 1
  dplyr::mutate(
    error = replace(error, error == 0, 1),
    error = ifelse(is.na(error), 1, error)
  ) %>%
  # we need to specifify which calibration curve should be used for what point
  dplyr::mutate(
    curve = ifelse(chroncontroltype == "Radiocarbon", "intcal20", "normal")
  ) %>%
  tibble::column_to_rownames("chroncontrolid") %>%
  dplyr::arrange(depth) %>%
  dplyr::select(
    chroncontrolage, error, depth, thickness, chroncontroltype, curve
  )

head(sel_chron_control_table)
```

```{r chron_control_show, echo=FALSE, results='asis', warning=FALSE, message=FALSE}
pander::pandoc.table(head(sel_chron_control_table))
```

```{r bchron, results='hide', warning=FALSE, message=FALSE}
i_multiplier <- 0.1 # increase to 5

n_iteration_default <- 10e3
n_burn_default <- 2e3
n_thin_default <- 8

n_iteration <- n_iteration_default * i_multiplier
n_burn <- n_burn_default * i_multiplier
n_thin <- max(c(1, n_thin_default * i_multiplier))

sel_bchron <-
  Bchron::Bchronology(
    ages = sel_chron_control_table$chroncontrolage,
    ageSds = sel_chron_control_table$error,
    positions = sel_chron_control_table$depth,
    calCurves = sel_chron_control_table$curve,
    positionThicknesses = sel_chron_control_table$thickness,
    iterations = n_iteration,
    burn = n_burn,
    thin = n_thin
  )
```

```{r bchron_figure, results='markup', warning=FALSE}
plot(sel_bchron)
```

#### Predict ages

```{r predic_ages, results='hide', warning=FALSE}
age_position <-
  Bchron:::predict.BchronologyRun(object = sel_bchron, newPositions = sel_level$depth)

age_uncertainties <-
  age_position %>%
  as.data.frame() %>%
  dplyr::mutate_all(., as.integer) %>%
  as.matrix()

colnames(age_uncertainties) <- sel_level$sample_id

sel_level_predicted <-
  sel_level %>%
  dplyr::mutate(
    age = apply(
      age_uncertainties, 2,
      stats::quantile,
      probs = 0.5
    )
  )

head(sel_level_predicted)
```

```{r level_predicted_diplay, echo=FALSE, results='asis', warning=FALSE, message=FALSE}
pander::pandoc.table(head(sel_level_predicted))
```

## Estimation Rate-of-Change

Here we use the the prepared data to estimate the rate of vegetation change. We
will use the method of the *binning with the mowing window*, *Shepard's 5-term filter* 
as data smoothing *Chi-squared coefficient* as dissimilarity coefficient.
This is again a toy example for a quick computation and we would recommend 
increasing the *randomisations* to 10.000 for any real estimation. 

```{r roc, results='hide', warning=FALSE, message=FALSE}
sel_roc <-
  RRatepol::fc_estimate_RoC(
    data_source_community = sel_counts_selected,
    data_source_age = sel_level_predicted,
    smooth_method = "none",
    DC = "chisq",
    Working_Units = "levels",
    standardise = FALSE
  )
```


```{r roc_figure, results='markup', echo=TRUE}
RRatepol::fc_plot_RoC_sequence(
  data_source = sel_roc
)
```

```{r}

```